| Decision Factor                                                                    | My Choice   | Reason (1 sentence)                                                                                                                                                   |
| ---------------------------------------------------------------------------------- | ----------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Which LLM followed my prompt structure most faithfully?                            | **ChatGPT** | ChatGPT adhered strictly to the 5-subsection format per layer and produced the most scannable, consistently structured output with clear markdown headers.            |
| Which LLM was most technically accurate (least hallucination)?                     | **Claude**  | Claude consistently used "likely," "probably," and "I suspect" for uncertain internal architecture, while ChatGPT stated Vespa.ai as fact and Gemini failed entirely. |
| Which LLM's output was most readable and well-organized?                           | **ChatGPT** | ChatGPT's bullet-pointed technology lists and consistent subsection ordering made it easier to scan and compare layers than Claude's narrative paragraphs.            |
| Which LLM handled the "honesty check" best (admitting when a layer doesn't apply)? | **Claude**  | Claude provided nuanced 4-tier ratings (critical/heavily/moderately/minimal) with justification, while ChatGPT used binary critical/not-critical assessments.         |
